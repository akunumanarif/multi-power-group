version: '3.9'
services:
  order-service:
    build:
      dockerfile: apps/order-service/Dockerfile
    container_name: mpg-order-service
    ports:
      - "3001:3001"
    environment:
      - KAFKA_BROKER=kafka:9092
      - DB_HOST=postgres  
      - DB_PORT=5432      
      - DB_USERNAME=postgres  
      - DB_PASSWORD=postgres  
      - DB_DATABASE=order_db  
      - DB_SYNCHRONIZE=true
    depends_on:
      - postgres
      - kafka
    networks:
      - app-network
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./logs:/app/logs

  notification-service:
    build:
      dockerfile: apps/notification-service/Dockerfile
    container_name: mpg-notification-service
    ports:
      - "3002:3002"
    depends_on:
      - kafka
    networks:
      - app-network
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./logs:/app/logs        

  postgres:
    image: postgres:15
    container_name: mpg-postgres
    restart: always
    environment:
      POSTGRES_USER: postgres      
      POSTGRES_PASSWORD: postgres   
      POSTGRES_DB: order_db
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      # - ./docker-entrypoint/init-notification-db.sh:/docker-entrypoint-initdb.d/init-notification-db.sh
    networks:
      - app-network

  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    restart: unless-stopped
    networks:
      - app-network

  kafka:
    image: wurstmeister/kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,INTERNAL://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,INTERNAL://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG4J_ROOT_LOGLEVEL: "INFO"
    networks:
    - app-network

  kafdrop:
    image: obsidiandynamics/kafdrop:3.30.0
    container_name: kafdrop
    depends_on:
      - kafka
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: kafka:9092 
      # KAFKA_PROPERTIES: "(bootstrap.servers=kafka:9092)"
      # JVM_OPTS: "-Xms32M -Xmx64M -Dkafka.brokerConnect=kafka:9092"
      SERVER_SERVLET_CONTEXTPATH: "/"
    networks:
      - app-network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    ports:
      - "9200:9200"
    networks:
      - app-network

  logstash:
    image: docker.elastic.co/logstash/logstash:8.15.0
    ports:
      - "5044:5044"
      - "9600:9600"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    environment:
      - LS_JAVA_OPTS=-Xmx256m -Xms256m
    depends_on:
      - elasticsearch
    networks:
      - app-network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - app-network

  filebeat:
    build:
      context: ./filebeat
      dockerfile: Dockerfile
    container_name: filebeat
    user: root
    volumes:
      - ./logs:/usr/share/filebeat/logs
    depends_on:
      - logstash
    networks:
      - app-network    

volumes:
  postgres-data:

networks:
  app-network:
    driver: bridge