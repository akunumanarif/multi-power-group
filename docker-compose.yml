version: '3.9'
services:
  order-service:
    build:
      dockerfile: apps/order-service/Dockerfile
    container_name: mpg-order-service
    ports:
      - "3001:3001"
    env_file:
      - .env
    depends_on:
      - postgres
      - kafka
    networks:
      - app-network
    restart: unless-stopped  
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./logs:/app/logs
      - ./\.env:/app/.env

  notification-service:
    build:
      dockerfile: apps/notification-service/Dockerfile
    container_name: mpg-notification-service
    ports:
      - "3002:3002"
    env_file:
      - .env
    depends_on:
      - kafka
    networks:
      - app-network
    restart: unless-stopped  
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./logs:/app/logs
      - ./\.env:/app/.env        

  postgres:
    image: postgres:15
    container_name: mpg-postgres
    restart: always
    env_file:
      - .env
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      # - ./docker-entrypoint/init-notification-db.sh:/docker-entrypoint-initdb.d/init-notification-db.sh
    networks:
      - app-network

  kafka:
    image: bitnami/kafka:3.7
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_CFG_LOG_FLUSH_INTERVAL_MESSAGES=10000
      - KAFKA_CFG_LOG_FLUSH_INTERVAL_MS=1000
      - KAFKA_CFG_LOG_RETENTION_HOURS=168
      - KAFKA_CFG_LOG_SEGMENT_BYTES=1073741824
      - KAFKA_CFG_LOG_RETENTION_CHECK_INTERVAL_MS=300000
      - KAFKA_CFG_GROUP_INITIAL_REBALANCE_DELAY_MS=0
    networks:
      - app-network
    restart: unless-stopped  

  kafdrop:
    image: obsidiandynamics/kafdrop:3.30.0
    container_name: kafdrop
    depends_on:
      - kafka
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: kafka:9092 
      SERVER_SERVLET_CONTEXTPATH: "/"
    restart: unless-stopped  
    networks:
      - app-network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    ports:
      - "9200:9200"
    restart: unless-stopped  
    networks:
      - app-network

  logstash:
    image: docker.elastic.co/logstash/logstash:8.15.0
    ports:
      - "5044:5044"
      - "9600:9600"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    environment:
      - LS_JAVA_OPTS=-Xmx256m -Xms256m
    depends_on:
      - elasticsearch
    restart: unless-stopped  
    networks:
      - app-network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    restart: unless-stopped  
    networks:
      - app-network

  filebeat:
    build:
      context: ./filebeat
      dockerfile: Dockerfile
    container_name: filebeat
    user: root
    volumes:
      - ./logs:/usr/share/filebeat/logs
    depends_on:
      - logstash
    restart: unless-stopped  
    networks:
      - app-network    

volumes:
  postgres-data:

networks:
  app-network:
    driver: bridge